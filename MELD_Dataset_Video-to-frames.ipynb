{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPuJjWUy0TEJABLpa/cfs5a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhuvod/Enhanced-Emotion-Recognition-using-V-MoE-/blob/main/MELD_Dataset_Video-to-frames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SqZ7Lkm_H1DE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "trw-WePOH4qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bf6c10-f0d7-43c7-a39d-dc1b59537521"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/drive/MyDrive/MELD_Dataset/train_splits THIS IS THE FILE PATH OF TRAINING DATA\n"
      ],
      "metadata": {
        "id": "51UzoqDGsZMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Frame Extraction Function\n",
        "def extract_frames(video_path, output_dir, utterance_id, emotion):\n",
        "    \"\"\"\n",
        "    Extract frames from video and organize them by emotion and utterance.\n",
        "\n",
        "    Parameters:\n",
        "    - video_path: path to the video file (e.g., 'dev/dia0_utt8.mp4')\n",
        "    - output_dir: base directory for saving frames (e.g., 'dataset/dev')\n",
        "    - utterance_id: ID of the utterance (e.g., '0_8')\n",
        "    - emotion: emotion label from CSV (e.g., 'angry')\n",
        "    \"\"\"\n",
        "    # Step 1: Create emotion directory\n",
        "    emotion_dir = os.path.join(output_dir, emotion.lower())\n",
        "    os.makedirs(emotion_dir, exist_ok=True)\n",
        "\n",
        "    # Step 2: Create utterance directory\n",
        "    utterance_dir = os.path.join(emotion_dir, f\"utterance_ID_{utterance_id}\")\n",
        "    os.makedirs(utterance_dir, exist_ok=True)\n",
        "\n",
        "    # Step 3: Open and validate video file\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    if not video.isOpened():\n",
        "        print(f\"Error opening video: {video_path}\")\n",
        "        return None, 0\n",
        "\n",
        "    # Step 4: Extract frames\n",
        "    frame_count = 0\n",
        "    success, frame = video.read()\n",
        "\n",
        "    while success:\n",
        "        # Save each frame as a JPG file\n",
        "        frame_path = os.path.join(utterance_dir, f\"frame_{frame_count:03d}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "        frame_count += 1\n",
        "        success, frame = video.read()\n",
        "\n",
        "    # Step 5: Cleanup\n",
        "    video.release()\n",
        "    return utterance_dir, frame_count"
      ],
      "metadata": {
        "id": "FGVe6-keH4ti"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/MELD_Dataset/train_sent_emo.csv')\n",
        "from google.colab import sheets\n",
        "# sheet = sheets.InteractiveSheet(df=data)"
      ],
      "metadata": {
        "id": "lY1SQTi7sUU-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = data.shape[0]\n",
        "num_rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWykEUe7ss6v",
        "outputId": "dfae326b-1cfc-4cc2-d13e-3c2f9cb36487"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9989"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/MELD_Dataset/train_splits'\n",
        "\n",
        "# Count video files (assuming they have .mp4 extension)\n",
        "video_count = len([f for f in os.listdir(folder_path) if f.endswith('.mp4')])\n",
        "\n",
        "print(f\"Number of video files in the folder: {video_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHhko3vI6yAH",
        "outputId": "f08dfb98-c371-4f94-e938-3157858e7626"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of video files in the folder: 4927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Helper Function to Parse Filenames\n",
        "import re\n",
        "def get_utterance_from_filename(filename):\n",
        "    \"\"\"Extract dialogue and utterance numbers from filename.\"\"\"\n",
        "    pattern = r'dia(\\d+)_utt(\\d+)\\.mp4'\n",
        "    match = re.match(pattern, filename)\n",
        "    if match:\n",
        "        dialogue_num = match.group(1)\n",
        "        utterance_num = match.group(2)\n",
        "        return f\"{dialogue_num}_{utterance_num}\"\n",
        "    return None"
      ],
      "metadata": {
        "id": "Zy7MJcbLtjOs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Main Processing Function\n",
        "def process_dataset(base_dir, csv_path, video_folder, output_folder):\n",
        "    \"\"\"Process all videos in a dataset split.\"\"\"\n",
        "    # Setup paths\n",
        "    video_dir = os.path.join(base_dir, video_folder)\n",
        "    frames_output_dir = os.path.join(base_dir, output_folder)\n",
        "    new_csv_path = os.path.join(base_dir, f\"{output_folder.split('/')[-1]}_processed.csv\")\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(frames_output_dir, exist_ok=True)\n",
        "\n",
        "    # Read CSV file and create emotion lookup dictionary\n",
        "    df = pd.read_csv(csv_path)\n",
        "    utterance_to_emotion = {}\n",
        "    for index, row in df.iterrows():\n",
        "        utterance_to_emotion[f\"{row['Dialogue_ID']}_{row['Utterance_ID']}\"] = row['Emotion']\n",
        "\n",
        "    # Process videos and create new CSV\n",
        "    with open(new_csv_path, 'w', newline='', encoding='utf-8') as new_csv:\n",
        "        fieldnames = ['Utterance_ID', 'Emotion', 'frame_path', 'num_frames']\n",
        "        writer = csv.DictWriter(new_csv, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Process each video file\n",
        "        video_files = [f for f in os.listdir(video_dir) if f.endswith('.mp4')]\n",
        "        for video_file in tqdm(video_files, desc=f\"Processing {output_folder} videos\"):\n",
        "            # Get video path\n",
        "            video_path = os.path.join(video_dir, video_file)\n",
        "\n",
        "            # Extract utterance_id from filename\n",
        "            utterance_id = get_utterance_from_filename(video_file)\n",
        "\n",
        "            if not utterance_id:\n",
        "                print(f\"Warning: Could not parse filename: {video_file}\")\n",
        "                continue\n",
        "\n",
        "            # Get emotion from CSV mapping\n",
        "            emotion = utterance_to_emotion.get(utterance_id)\n",
        "\n",
        "            if not emotion:\n",
        "                print(f\"Warning: No emotion found for utterance ID: {utterance_id}\")\n",
        "                continue\n",
        "\n",
        "            # Extract frames and get info\n",
        "            frame_dir, num_frames = extract_frames(video_path, frames_output_dir,\n",
        "                                                 utterance_id, emotion)\n",
        "\n",
        "            if frame_dir and num_frames > 0:\n",
        "                writer.writerow({\n",
        "                    'Utterance_ID': utterance_id,\n",
        "                    'Emotion': emotion,\n",
        "                    'frame_path': frame_dir,\n",
        "                    'num_frames': num_frames\n",
        "                })"
      ],
      "metadata": {
        "id": "kYBR-zeetqZR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Run the Processing\n",
        "BASE_DIR = \"/content/drive/MyDrive/MELD_Dataset\"  # Update this path\n",
        "\n",
        "DATASET_MAPPING = [\n",
        "    {\"csv_path\": os.path.join(BASE_DIR, \"test_sent_emo.csv\"),\n",
        "     \"video_folder\": \"output_repeated_splits_test\",\n",
        "     \"output_folder\": \"dataset/test\"},\n",
        "]\n",
        "\n",
        "for dataset in DATASET_MAPPING:\n",
        "    print(f\"Processing {dataset['output_folder']} split...\")\n",
        "    process_dataset(\n",
        "        BASE_DIR,\n",
        "        dataset[\"csv_path\"],\n",
        "        dataset[\"video_folder\"],\n",
        "        dataset[\"output_folder\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "95RkLtGp5FGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}